Télécharger Hadoop

	curl -O https://archive.apache.org/dist/hadoop/core/hadoop-2.6.4/hadoop-2.6.4.tar.gz

Dézipper
	sudo tar -xvf hadoop-2.6.4.tar.gz

Donner la main au user spark sur le répertoire hdfs : 
	sudo chown -R spark ./hadoop-2.6.4

Voir la configuration
	cd ./hadoop-2.6.4/etc/hadoop


Vous devez créer les répertoires sur chaque machine

	mkdir /home/spark/hdfs-data/	
	mkdir /home/spark/hdfs-data/nn
	mkdir /home/spark/hdfs-data/dn




Quatre fichiers importants
	core-site.xml	Information concernant tous les aspects d’Hadoop
	hdfs-site.xml	Information concernant HDFS
	masters		Liste des @ip pour les namenode secondaires
	slaves		Liste des @ip pour les slaves


On peut supprimer core-site.xml et hdfs-site.xml pour juster copier / coller la version du github : 
	rm core-site.xml
	rm hdfs-site.xml

	vi core-site.xml 	puis copier le core-site.xml du github
	vi hdfs-site.xml 	puis copier le hdfs-site.xml du github
	
